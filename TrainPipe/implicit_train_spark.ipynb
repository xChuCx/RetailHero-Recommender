{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "from pyspark import sql, SparkConf, SparkContext\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add zeros to k items length\n",
    "def add_to_k(lst, k):\n",
    "    return lst + [0] * max(k - len(lst), 0)\n",
    "\n",
    "# precision at k\n",
    "def precision_at_k(r_true_arr, k):\n",
    "    return np.sum(r_true_arr[:k]) / k\n",
    "\n",
    "\n",
    "# average precision at k\n",
    "def average_precision_at_k(r_true_arr, k):\n",
    "    apk = 0\n",
    "    for n in range(0, k):\n",
    "        apk += precision_at_k(r_true_arr, n + 1) * r_true_arr[n]\n",
    "    if np.sum(r_true_arr[:k]) != 0:\n",
    "        return (apk) / k\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# average normed precision at k\n",
    "def average_normed_precision_at_k(r_true_arr, k, n_true):\n",
    "    apk = 0\n",
    "    apk_ideal = n_true / k\n",
    "    \n",
    "    for n in range(0, k):\n",
    "        apk += precision_at_k(r_true_arr, n + 1) * r_true_arr[n]\n",
    "    if np.sum(r_true_arr[:k]) != 0:\n",
    "        return ((apk) / k) / apk_ideal\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerated_dict(values):\n",
    "    enum_dict = {}\n",
    "    reverse_dict = {}\n",
    "    \n",
    "    for n, value in enumerate(values):\n",
    "        enum_dict[value] = n\n",
    "        reverse_dict[n] = value\n",
    "        \n",
    "    return enum_dict, reverse_dict\n",
    "\n",
    "\n",
    "def predict_user(model, user_id, products, product_dict, reverse_product_dict, matrix_shape):\n",
    "    enum_clients = np.zeros(len(products))\n",
    "    enum_products = np.array([product_dict[product] for product in products])\n",
    "\n",
    "    sparse_matrix = scipy.sparse.csr_matrix((np.ones(shape=(len(enum_clients))), \n",
    "                                             (enum_clients, enum_products)), \n",
    "                                            shape=matrix_shape)\n",
    "    \n",
    "    rec = model.recommend(0, sparse_matrix, N=30, recalculate_user=True,\n",
    "                     filter_already_liked_items=False)\n",
    "    \n",
    "    return [[user_id, reverse_product_dict[r[0]]] for r in rec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"Read_CSV\").setAll([('spark.executor.memory', '6g'), ('spark.executor.cores', '7'), ('spark.cores.max', '7'), ('spark.driver.memory','16g'), ('spark.driver.maxResultSize','2g')])\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load purchases\n",
    "purchases = sqlContext.read.format(\"csv\").option(\"header\", \"true\").load(\"data/purchases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем рекомендовать только \"современное\"\n",
    "contemporary_items = purchases.select(purchases.product_id)\\\n",
    "                                .where(purchases.transaction_datetime < \"2019-02-15 00:00:00\")\\\n",
    "                                .distinct()\n",
    "\n",
    "contemporary_items = [row['product_id'] for row in contemporary_items.collect()]\n",
    "\n",
    "purchases = purchases.filter(purchases.product_id.isin(contemporary_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выберем только пользователей с более, чем одной транзакцией\n",
    "transactions_cnt = purchases\\\n",
    "                    .groupby(\"client_id\")\\\n",
    "                    .count()\n",
    "\n",
    "transactions_cnt = transactions_cnt.filter(transactions_cnt[\"count\"] > 1)\n",
    "multi_trans_users = [row['client_id'] for row in transactions_cnt.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "test_users = np.random.choice(multi_trans_users, 1).tolist()\n",
    "\n",
    "test = purchases.filter(purchases.client_id.isin(test_users))\n",
    "\n",
    "train = purchases.filter(~purchases.client_id.isin(test_users))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_dic = [row['client_id'] for row in purchases.select(purchases.client_id).distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_dic = [row['product_id'] for row in purchases.select(purchases.product_id).distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# клиенты только из train, а продукты из всего набора данных\n",
    "client_dict, reverse_client_dict = enumerated_dict(client_dic)\n",
    "\n",
    "product_dict, reverse_product_dict = enumerated_dict(product_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем словари, чтобы была возможность создать матрицу\n",
    "with open(\"x5_dic.pkl\", \"wb\") as f:\n",
    "    pickle.dump((client_dict, reverse_client_dict, \n",
    "                 product_dict, reverse_product_dict), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum = train.select(train.client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_pr = train.select(train.product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_clients = np.concatenate(\n",
    "                    enum.select(\"client_id\").rdd.glom().map(\n",
    "                      lambda x: np.array([client_dict[elem[0]] for elem in x]))\n",
    "                    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_products = np.concatenate(\n",
    "                    enum_pr.select(\"product_id\").rdd.glom().map(\n",
    "                      lambda x: np.array([product_dict[elem[0]] for elem in x]))\n",
    "                    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим размер матрицы\n",
    "matrix_shape = (max(reverse_client_dict.keys()) + 1, max(reverse_product_dict.keys()) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = scipy.sparse.coo_matrix((np.ones(shape=(len(enum_clients))), \n",
    "                                         (enum_clients, enum_products)), \n",
    "                                        shape=matrix_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c828ce768fc4f9ca25bf6064e22d7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = implicit.nearest_neighbours.TFIDFRecommender(K=1)\n",
    "\n",
    "# Fit model\n",
    "model.fit((sparse_matrix.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump model to ./tmp/implicit/\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"./tmp/implicit/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print(\"Dump model to \" + out_dir)\n",
    "pickle.dump(model, open(out_dir + \"/model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"./tmp/implicit/model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x5_dic.pkl\", \"rb\") as f:\n",
    "    (\n",
    "        client_dict,\n",
    "        reverse_client_dict,\n",
    "        product_dict,\n",
    "        reverse_product_dict,\n",
    "    ) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_transactions = test_data.drop_duplicates(subset=\"client_id\", keep=\"last\")[\"transaction_id\"]\n",
    "test_validation = test_data[test_data[\"transaction_id\"].isin(last_transactions)]\n",
    "test_data = test_data[~test_data[\"transaction_id\"].isin(last_transactions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xchucx/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7e247de8a64b328fe896db9733bf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Определим размер матрицы\n",
    "matrix_shape = (max(reverse_client_dict.keys()) + 1, max(reverse_product_dict.keys()) + 1)\n",
    "\n",
    "# Рекомендации для отсутствующих пользователей\n",
    "recommendations = []\n",
    "\n",
    "for test_client in tqdm_notebook(test_data[\"client_id\"].unique()):\n",
    "    products = test_data[test_data[\"client_id\"]==test_client][\"product_id\"]\n",
    "    rec = predict_user(model, test_client, products, product_dict, reverse_product_dict,\n",
    "                       (1, matrix_shape[1]))\n",
    "    recommendations.extend(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# датафрейм с покупками в реальности\n",
    "reality = test_validation[[\"client_id\", \"product_id\"]].copy()\n",
    "reality.loc[:, \"is_buyed\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = pd.DataFrame(recommendations, columns=[\"client_id\", \"product_id\"])\\\n",
    "            .merge(reality, \n",
    "                   on=[\"client_id\", \"product_id\"], \n",
    "                   how=\"left\", \n",
    "                   sort=False)\\\n",
    "            .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь с количеством покупок на валидации\n",
    "real_dict = reality.groupby(by=\"client_id\")[\"is_buyed\"].sum().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([precision_at_k(i, 30) for i in \n",
    "         rec_df.groupby(by=\"client_id\", sort=False)[\"is_buyed\"].apply(list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([average_precision_at_k(add_to_k(i, 30), 30) for client, i in \n",
    "         rec_df.groupby(by=\"client_id\")[\"is_buyed\"].apply(list).reset_index().values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([average_normed_precision_at_k(add_to_k(i, 30), 30, real_dict.get(client, 0)) for client, i in \n",
    "         rec_df.groupby(by=\"client_id\")[\"is_buyed\"].apply(list).reset_index().values])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
